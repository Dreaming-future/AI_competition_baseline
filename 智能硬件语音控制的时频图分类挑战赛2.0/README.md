# 智能硬件语音控制的时频图分类挑战赛2.0

比赛地址：http://challenge.xfyun.cn/topic/info?type=time-frequency-2022&option=ssgy

## 一、赛事背景

2014年11月，亚马逊推出了一款全新概念的智能音箱Echo，通过语音指令交互控制硬件设备。截止2016年4月，Echo的累计销量已经突破300万台。2017年12月累计数千万台。亚马逊Echo音箱的推出标志着以语音交互为实用化的落地方案。

以智能音箱为代表的声控智能硬件在我国已经得到了商业化的大规模推广。2020年我国占有全球智能音箱销售量的51%，位居全球第一，而同期美国的份额从44%下降到了24%。

## 二、赛事任务

赛题提供具有24句语音交互指令的语音时频谱数据集(spectrogram dataset)，选手需要完成搭建网络模型，基于密集多层网络、卷积网络和循环网络等基本结构的组合，进行有效预测。

## 三、评审规则

### 1.数据说明

本次比赛为参赛选手提供了语音信号及其对应的语句标签。出于数据安全保证的考虑，所有数据均为脱敏处理后的数据。

### 2.评估指标

本模型依据提交的结果文件，采用Macro-F1进行评价。

### 3.评测及排行

1、初赛和复赛均提供下载数据，选手在本地进行算法调试，在比赛页面提交结果。

2、每支团队每天最多提交3次。

3、排行按照得分从高到低排序，排行榜将选择团队的历史最优成绩进行排名。

## 四、作品提交要求

1、文件格式：按照csv格式提交测试结果

2、文件大小：无要求

3、文件详细说明：

1) 编码为UTF-8

2) 提交格式见提交示例

## 五、赛程规则

本赛题实行一轮赛制

### 赛程周期 7月1日-8月1日

1、7月1日10：00发布相关数据集（即开启比赛榜单）

2、比赛作品提交截止日期为8月1日17：00

### 现场答辩

1、最终前三名团队将受邀参加科大讯飞全球1024开发者节并于现场进行答辩

2、答辩以（10mins陈述+5mins问答）的形式进行

3、根据作品成绩和答辩成绩综合评分（作品成绩占比70％，现场答辩份数占比30％）

## 六、奖项设置

- 入围决赛
  - 科大讯飞1024开发者节全场通票
  - 决赛入围证书
  - 科大讯飞创孵基地绿色入驻通道
  - A.I.服务市场入驻特权
- 决赛胜出
  - 决赛奖金，各赛道TOP3选手将阶梯获得赛道奖金，第一名5000元、第二名3000元、第三名2000元。
  - 参与1024全球开发者节颁奖盛典，现场授予奖金、证书与定制奖杯
  - A.I.全链创业扶持
  - 绿色就业通道&讯飞Offer



## 七、尝试Tricks和思路

- [ ] 尝试多用数据增强

- [x] 尝试用现有的权重进行迁移学习

- [x] 尝试利用LabelSmooth的损失

- [x] 尝试用多模型集成，模型融合等方法

- [ ] 尝试改变图像的分辨率，原先是450x750

  > 450x750其实是一个很奇妙的数据，在图片中，大概来说是500x800,450x750讲边缘数据给剔除之后，也就是边缘的噪声得到最后的结果，这样的方法是比较有可信度的

- [ ] 尝试增大batchsize进行运行得到结果，从5->8

- [ ] 尝试利用大模型进行训练

## 八、详细参数以及运行

**数据增强处理**

```bash
transform_train = A.Compose([
        A.RandomCrop(450, 750),
    ])
```

后续增加数据增强，我发现从结果上来看，由于我们的图片中亮度变化比较明显，如果对亮度进行变化的话，我们的数据增强几乎是没什么效果的，个人感觉对比度也是，所以增加的数据增强主要是对图像的平移，或者掩盖等等。如果结果不错的话，再考虑用亮度和对比度的增强进行测试

增加了A.CoarseDropout(p=0.5)以后，结果提高了1%左右

```bash
transform_train = A.Compose([
            A.RandomCrop(450, 750),
            A.CoarseDropout(p=0.5),
            # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=0, p=0.5),
            # A.RandomBrightnessContrast(p=0.5),
        ])
```

**ResNet18**

首先借鉴baseline中的ResNet18进行训练，然后加上自己的框架和一点点修改进行训练，第一次训练达到了91.5%的评分

```bash
CUDA_VISIBLE_DEVICES=3 python train.py -f --cuda --net ResNet18 --epochs 50 -bs 5 -lr 0.001
```

**训练方式**

```bash
CUDA_VISIBLE_DEVICES=0 python train.py -f --cuda --net Model --epochs 50 -bs 5 -lr 0.001 -fe 5
```

结果会发现，我们用小模型的训练往往能得到不错的结果，特别是EfficientNetv2系列的模型，在验证集中能得到比较高的准确率

这之中都是利用预训练模型进程测试的，因为含有一定量知识的模型才能得到更好的结果，并且在下列模型中，都先冻结训练了5个迭代

除此之外，添加了早停策略，防止过拟合



这里展示的是模型的最优结果

|     使用模型      |  迭代次数   |             训练参数             | 训练集ACC | 验证集ACC |
| :---------------: | :---------: | :------------------------------: | :-------: | :-------: |
|     ResNet18      | epochs = 50 | AdamW,lr = 0.0005,batch-size = 8 |   99.90   |   97.12   |
|    ConvNeXt-T     | epochs = 50 | AdamW,lr = 0.0005,batch-size = 8 |           |           |
| EfficientNetv2-T  | epochs = 50 | AdamW,lr = 0.0005,batch-size = 8 |   99.90   |   91.12   |
| EfficientNetv2-b0 | epochs = 50 | AdamW,lr = 0.0005,batch-size = 8 |   99.90   |   96.63   |
| EfficientNetv2-b1 | epochs = 50 | AdamW,lr = 0.0005,batch-size = 8 |   99.90   |   95.67   |





实际上现有模型都是小模型进行训练，之后也可以尝试利用大模型查看能否得到比较好的结果



## 九、提交结果

2022.7.15，目前排名第7，得分0.93121

![在这里插入图片描述](https://img-blog.csdnimg.cn/7cdc233e403d4cdf86b503a504a39bfa.png#pic_center)

2022.7.15，目前排名第5，得分0.94377，这一次只加了一个数据增强就得到了不错的结果

![在这里插入图片描述](https://img-blog.csdnimg.cn/f572b323e840455ea798d7c0a1dc1429.png#pic_center)

|  ID  |   状态   |  评分   |                 提交文件名                 |                           提交备注                           |      提交者       |      提交时间       |
| :--: | :------: | :-----: | :----------------------------------------: | :----------------------------------------------------------: | :---------------: | :-----------------: |
|  1   | 返回分数 | 0.94377 |     submit_ensemble_07-15-16-56-00.csv     | 集成多个Efficientv2系列的模型，加上ResNet18小模型，加上随机掩盖数据增强的结果 | 擅长射手的pikachu | 2022-07-15 17:14:56 |
|  2   | 返回分数 | 0.93121 |     submit_ensemble_07-15-01-03-09.csv     | 集成多个Efficientv2系列的模型，加上ResNet18小模型，无数据增强的结果 | 擅长射手的pikachu | 2022-07-15 09:53:24 |
|  3   | 返回分数 | 0.93121 | submit_EfficientNetv2-S_07-15-01-03-09.csv | 利用三个模型ConvNeXt-T,ResNet18,EfficientNetv2-S，无数据增强的结 | 擅长射手的pikachu | 2022-07-15 01:04:40 |
|  4   | 返回分数 | 0.90679 |             sub_convnext-T.csv             | 利用ConvNeXt-T模型，在改进的基础上进行训练，无数据增强的结果 | 擅长射手的pikachu | 2022-07-14 22:20:30 |
|  5   | 返回分数 | 0.9145  |                  sub.csv                   | 利用baseline中的ResNet18模型，在改进的基础上进行训练，最后测试结果 | 擅长射手的pikachu | 2022-07-14 16:54:44 |